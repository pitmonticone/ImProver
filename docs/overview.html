<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Improof - Proof Optimization Project</title>
  <link rel="stylesheet" href="https://unpkg.com/@picocss/pico@1.4.0/css/pico.min.css">
  <link rel="stylesheet" href="assets/css/style.css">
</head>
<body>
  <main class="container">
    <header>
      <nav>
        <ul>
          <li><strong>ImProof</strong></li>
          <li><a href="index.html">Home</a></li>
          <li><a href="overview.html">Overview</a></li>
          <li><a href="experiments.html">Results</a></li>
          <li><a href="team.html">Team</a></li>
          <!-- <li><a href="https://github.com/riyazahuja/Automated-Proof-Rewriting">Code</a></li> -->
        </ul>
      </nav>
    </header>
    <article>
      <header>
        <h1>ImProof Overview</h1>
        <p>A high-level overview of ImProof and its framework, with results and usage guides.</p>
      </header>
        <section>
          <h2>Background</h2>
          <p>We present ImProof, a LLM-powered Agent for proof rewriting tasks, built around a general-purpose neural theorem proving framework. </p>
          <p>ImProof allows for arbitrary Lean 4 code to be optimized for an arbitrary metric, empowering users to freely and automatically optimize their formal proofs by just providing a lambda and prompt. It is built upon an NTP framework that allows for strict control over how LLMs interface with theorems, providing a higher degree of accuracy and control over proof (re)writing tasks.</p>
          <p>With the rise in popularity of modern interactive theorem provers, there is a need for greater control over how formal proof are structured and developed. </p>
          <p>By allowing for modular control over what metric to rewrite a given proof for, ImProof shows that given enough guardrails, SOTA language models can perform such optimization to a high degree of accuracy and effectiveness.</p>
        <p>Some metrics we explore include:</p>
        <ul>
          <li>
            <strong>Length:</strong>
            <p>Optimizing for length allows mathematicians to write more concise and, by some definitions, more efficient proofs.</p>
          </li>
          <li>
            <strong>Modularity:</strong>
            <p>By maximizing the number of reusable, independent subproofs that make up a given proof tree, we can epistemically improve proofs and practically increase the number of theorems in a database by separating all independent subproofs as standalone lemmas.</p>
          </li>
          <li>
            <strong>Readability:</strong>
            <p>Optimizing for more readable proofs (according to a quantifiable standard of readability) facilitates better understanding of complex proofs and provides a distinct pedagogical advantage.</p>
          </li>
          <li>
            <strong>Similarity:</strong>
            <p>Creating new proofs that minimize similarity to the original proof enables multiple distinct strategies to prove the same theorem, offering new insights into proof structure and methods.</p>
          </li>
          <li>
            <strong>Completion:</strong>
            <p>One may reframe the complete neural theorem proving problem (i.e. fully generating proofs from scratch) as a "metric" to optimize for.</p>
          </li>
        </ul>
        
        <p>Optimizing for these arbitrary auxilary metrics, on top of simply generating semantically and syntactically correct proofs, allows for mathematicians and ML researchers to have far greater control over netural theorem proving and proof optimization tasks,
          enabling more efficient, readable, intuitive, and reusable proof generation at scale.</p>
      </section>
      <section>
        <h2>Results</h2>
        <p>Our tool has shown significant improvements in all tested metrics from raw SOTA LLM prompting. Final rigorous testing and data experimentation is underway and expected to be fully completed and published by September 2024.</p>
        <p>Preliminary experiments will be redhave been released on the AlphaProof/IMO2024 data. See <a href="experiments.html">experiments</a> to learn more.</p>
      </section>
      <section>
        <h2>Installation and Usage</h2>
        <p>For a more detailed usage guide (including method and custom metric configurations), follow the instructions in the <a href="https://github.com/riyazahuja/Automated-Proof-Rewriting/blob/main/README.md">README</a>.</p>
        <ol>
          <li>
            <p>Clone the <a href="https://github.com/riyazahuja/Automated-Proof-Rewriting">Github Repo</a> locally on your machine and download the python packages from <code>requirements.txt</code> (Requires Python 3.11+)</p>
          </li>
          <li>
            <p>Set up JSON build configuration in <code>./configs/</code>. For example:
              <pre><code>[
  {
      "path": "/Users/user/Desktop/lean-project",
      "lean": "leanprover/lean4:v4.9.0",
      "name": "LeanProject",
      "import_file": "LeanProject.lean",
      "imports": ["LeanProject"]
  },
  {
      "repo": "https://github.com/leanprover-community/mathlib4",
      "commit": "v4.9.0",
      "lean": "leanprover/lean4:v4.9.0",
      "name": "mathlib",
      "import_file": "Mathlib.lean",
      "imports": ["Mathlib"],
      "build": false
  }
]</code></pre>
              <p>Note that the built Lean 4 projects must be on version 4.9.0+</p>
          </li>
          <li>
            <p>Run the build script and cache the outputs in <code>./.cache/</code> by running:</p>
            <p><pre><code>python scripts/build.py --config configs/CONFIG_FILE_NAME.json</code></pre></p>
          </li>
          <li>
            <p>Configure the run parameters using the <code>get_methods</code> and <code>get_improof</code> functions in your script by importing from <code>./benchmark/tools.py</code></p>
            <p>For configuring these parameters with custom tunings and custom metrics, see the <a href="https://github.com/riyazahuja/Automated-Proof-Rewriting/blob/main/README.md">README</a></p>
          </li>
          <li>
            <p>Use <code>getRepo</code> to retrieve the cached repo information and <code>benchmark_repo</code>,<code>benchmark_file</code>, or <code>benchmark_file</code> to run your repo, file, or theorem respectively with the aforementioned parameter settings.
          </li>
          <li>
            <p>Optionally export to <code>.csv</code> using <code>save_to_csv</code>.
          </li>
        </ol>
      </section>
    </article>
    <footer>
      <p>Â© 2024 Proof Optimization Project</p>
    </footer>
  </main>
</body>
</html>
