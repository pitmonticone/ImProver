<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>AlphaProof Experiment - Proof Optimization Project</title>
  <link rel="stylesheet" href="https://unpkg.com/@picocss/pico@1.4.0/css/pico.min.css">
  <link rel="stylesheet" href="../assets/css/style.css">
  <script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>
<body>
  <main class="container">
    <header>
      <nav>
        <ul>
          <li><strong>ImProver</strong></li>
          <li><a href="../index.html">Home</a></li>
          <li><a href="../overview.html">Overview</a></li>
          <li><a href="../experiments.html">Results</a></li>
          <li><a href="../team.html">Team</a></li>
          <li><a href="https://github.com/riyazahuja/Automated-Proof-Rewriting">Code</a></li>
        </ul>
      </nav>
    </header>
    <article>
      <header>
        <h1>ImProver Ablations</h1>
      </header>
      <section>
        <h2>Overview</h2>
        <p>There are over 8640 possible parameter combinations, and we aim to define ImProver such that its specification is the optimal combination with respect to the Improvement score. To do this, we employ a factorial testing strategy with the following testing groups using the length metric:</p>
        <ul>

          <li><strong>GPT-4o-mini/GPT-4o: </strong>This varies the GPT-4o model, outputting a <code>string</code> with no other features.



          <li><strong>Output and CoS: </strong> We evaluate the effects of different output formatting styles (<code>string</code>, <code>string list</code>, <code>string tree</code>) and CoS (True, False), with the model fixed as GPT-4o, with no other features enabled.
          
          
          <li><strong>Example Retrieval: </strong> We evaluate the effects of increasing the number of examples provided (multi-shot prompting) in the range of 0,3,5,7, and 10, with the model fixed as GPT-4o, CoS and output formatting fixed as the best combination from the previous test, and no other features enabled.
          
          
          <li><strong>Sampling Method: </strong>Here, we evaluate the effects of best-of-n and refinement for a fixed n=5. Additionally we test on the refinement cases if forwarding the most recent iteration result, or all previous iteration results is the best, and if we should keep the best out of the iterations, or the most recent. The model is fixed as GPT-4o, CoS, output formatting, and examples are fixed as the best combination from the previous test, and no other features enabled.
          
          
          <li><strong>$n$ and Model: </strong>Here, we evaluate the effects of larger n values and different models. We test n=3,5,7,10,15 on GPT-4o and GPT-4o-mini, as well as n=20 for GPT-4o-mini (as it is of a far lower token cost). CoS, output formatting, examples, and sampling method are fixed as the best combination from the previous test, and no other features enabled.
          
          
          <li><strong>Combos and RAG: </strong> We evaluate combination methods <code>refinement(best_of_m',m)</code> and <code>best_of_m'(refinement(m))</code>, for \(m\neq m'\) with \(mm'\) equal to the optimal value \(m\) from the previous test. We also test the effect of enabling document retrieval. Model, CoS, output formatting, examples, n, and sampling method are fixed as the best combination from the previous test.
          
        </ul>
        
        
        <p>We evaluate our ablations on a subset of MIL. However, due to the increase in model calls for larger n values, we switch a representative sample of this subset for some test groups. Namely, GPT-4o-mini, GPT-4o, Output and CoS, Example Retrieval, and Sampling Method are tested on the 133 theorems in the solutions of <code>C03_Logic</code>, <code>C04_Sets_and_Functions</code>, and <code>C05_Elementary_Number_Theory</code>. \(n\) and Model are tested on 55 theorems from a representative sample of the aforementioned, and Combos and RAG are tested on a representative sample of 32 theorems from the aforementioned.
      </section>
      <section>
        <h2>Results</h2>
       
        <table>
          <tr>
              <td></td>
              <td>Improvement</td>
              <td>Nonempty Improve.</td>
              <td>Accuracy</td>
              <td>Improved Acc.</td>
          </tr>
          <tr>
              <td>GPT-4o-mini</td>
              <td>0</td>
              <td>0</td>
              <td>3.62%</td>
              <td>0%</td>
          </tr>
          <tr>
              <td>GPT-4o</td>
              <td>7.03</td>
              <td>19.67</td>
              <td>35.77%</td>
              <td>15.33%</td>
          </tr>
          <tr>
              <td>+ Output and CoS</td>
              <td>8.04 / 6.31</td>
              <td>12.38 / 14.17</td>
              <td>64.96% / 44.53%</td>
              <td>21.17% / 16.06%</td>
          </tr>
          <tr>
              <td>+ Example Retrieval</td>
              <td>9.34 / 5.67</td>
              <td>14.7 / 8.44</td>
              <td>63.5% / 67.15%</td>
              <td>21.9% / 16.79%</td>
          </tr>
          <tr>
              <td>+ Sampling Method</td>
              <td>15.35 / 9.34</td>
              <td>18.44 / 14.7</td>
              <td>83.21% / 63.5%</td>
              <td>36.5% / 21.9%</td>
          </tr>
          <tr>
              <td>+ \(n\) and Model</td>
              <td>23.51 / 3.65</td>
              <td>26.28 / 4.63</td>
              <td>89.47% / 78.95%</td>
              <td>45.61% / 8.77%</td>
          </tr>
          <tr>
              <td>+ Combos and RAG</td>
              <td>34.88 / 28.25</td>
              <td>57.56 / 33.48</td>
              <td>60.61% / 84.38%</td>
              <td>54.55% / 53.12%</td>
          </tr>
          <tr>
              <td><b>ImProver</b></td>
              <td><b>34.88</b></td>
              <td><b>57.56</b></td>
              <td><b>100%</b></td>
              <td><b>54.55%</b></td>
          </tr>
      </table>
      Where each cell has <code>best</code>/<code>worst</code> signifying the best and worst parameter combinations for each testing group, with respect to their Improvement score.
<p></p>
      <details>
        <summary>Readability Ablation</summary>

<p>We additionally examine the effects of disabling CoS on readability optimization tasks, as the previous study focused on length optimization tasks, and we speculate that CoS has a high impact on the performance of readability optimization tasks, as the proof states that are embedded due to CoS seem to be a critical aspect to generating the explicit declarations that the readability metric measures.</p>
<table>
  <tr>
      <td></td>
      <td>Improvement</td>
      <td>Nonempty Improve.</td>
      <td>Accuracy</td>
      <td>Improved Acc.</td>
  </tr>
  <tr>
      <td>GPT-4o</td>
      <td>4.97</td>
      <td>15.89</td>
      <td>37.5%</td>
      <td>12.5%</td>
  </tr>
  <tr>
      <td>ImProver, CoS Disabled</td>
      <td>9.23</td>
      <td>24.61</td>
      <td>100.0%</td>
      <td>28.12%</td>
  </tr>
  <tr>
      <td><b>ImProver</b></td>
      <td><b>16.69</b></td>
      <td><b>31.42</b></td>
      <td><b>100.0%</b></td>
      <td><b>46.88%</b></td>
  </tr>
</table>


      </details>


      <p>Raw data can be found and downloaded <a href="https://github.com/riyazahuja/ImProver/tree/main/benchmark/data/parameter_tuning">here.</a></p>
      </section>

    </article>
    <footer>
      <p>Â© 2024 ImProver</p>
    </footer>
  </main>
</body>
</html>
